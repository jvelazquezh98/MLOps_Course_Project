# Gu铆a de Uso de Scripts de Evaluaci贸n y Visualizaci贸n

Este documento explica c贸mo usar los nuevos scripts creados para completar los puntos faltantes del proyecto.

##  1. Visualizaci贸n de Resultados (`src/visualization/plot_results.py`)

### Descripci贸n
Genera visualizaciones comprehensivas de los resultados de modelos ML, incluyendo:
- Matrices de confusi贸n
- Curvas ROC
- Curvas Precision-Recall
- Distribuciones de predicciones
- Importancia de features

### Uso B谩sico

```bash
# Generar todas las visualizaciones para un modelo
python -m src.visualization.plot_results generate-all-plots \
  --predictions-path data/processed/predictions.csv \
  --model-name "random_forest" \
  --output-dir reports/figures
```

### Ejemplos

```bash
# Con modo debug
python -m src.visualization.plot_results generate-all-plots \
  --predictions-path data/processed/predictions.csv \
  --model-name "xgboost" \
  --output-dir reports/figures/xgb \
  --debug

# Para modelo espec铆fico
python -m src.visualization.plot_results generate-all-plots \
  --predictions-path data/processed/rf_predictions.csv \
  --model-name "rf_v1" \
  --output-dir reports/figures/rf_v1
```

### Salidas Generadas
- `confusion_matrix_{model_name}.png` - Matriz de confusi贸n
- `roc_curve_{model_name}.png` - Curva ROC con AUC
- `precision_recall_{model_name}.png` - Curva Precision-Recall
- `prediction_distribution_{model_name}.png` - Distribuci贸n de probabilidades

---

##  2. Comparaci贸n de Modelos (`src/evaluation/compare_models.py`)

### Descripci贸n
Compara autom谩ticamente m煤ltiples modelos ML y genera:
- Tabla comparativa de m茅tricas
- Gr谩ficos de barras comparativos
- Gr谩ficos radar
- Reporte de texto con rankings

### Uso B谩sico

```bash
# Comparar todos los modelos en el directorio de m茅tricas
python -m src.evaluation.compare_models compare \
  --metrics-dir reports/metrics \
  --output-dir reports/comparison
```

### Ejemplos

```bash
# Con modo debug
python -m src.evaluation.compare_models compare \
  --metrics-dir reports/metrics \
  --output-dir reports/comparison \
  --debug

# Directorio personalizado
python -m src.evaluation.compare_models compare \
  --metrics-dir models/experiment_metrics \
  --output-dir reports/model_comparison_2024
```

### Salidas Generadas
- `model_comparison.csv` - Tabla CSV con todas las m茅tricas
- `metrics_comparison_bar.png` - Gr谩fico de barras comparativo
- `metrics_comparison_radar.png` - Gr谩fico radar comparativo
- `comparison_report.txt` - Reporte detallado en texto

### Formato de Entrada
Los archivos JSON de m茅tricas deben tener esta estructura:

```json
{
  "model": "RandomForest",
  "metrics": {
    "accuracy": 0.85,
    "precision": 0.82,
    "recall": 0.88,
    "f1": 0.85,
    "AUC_test_final": 0.90
  }
}
```

---

##  3. Documentaci贸n de Notebooks (`src/documentation/notebook_documenter.py`)

### Descripci贸n
Agrega documentaci贸n inline detallada a notebooks Jupyter de forma automatizada.

### Comandos Disponibles

#### 3.1 Agregar Encabezado

```bash
python -m src.documentation.notebook_documenter add-header \
  notebooks/01_eda.ipynb \
  --title "An谩lisis Exploratorio de Datos" \
  --author "Tu Nombre" \
  --objective "Explorar y entender el dataset" \
  --description "An谩lisis detallado de distribuciones y correlaciones"
```

#### 3.2 Generar Plantilla de Documentaci贸n

```bash
# Analiza el notebook y genera una plantilla JSON
python -m src.documentation.notebook_documenter generate-template \
  notebooks/01_eda.ipynb \
  --output-path notebooks/01_eda_doc_template.json
```

Esto genera un archivo JSON que puedes editar:

```json
{
  "notebook_name": "01_eda",
  "sections": [
    {
      "number": 1,
      "title": "Carga de Datos",
      "objective": "[COMPLETAR: Objetivo de esta secci贸n]",
      "description": "[COMPLETAR: Descripci贸n detallada]",
      "num_cells": 3
    }
  ]
}
```

#### 3.3 Aplicar Documentaci贸n

```bash
# Aplica la plantilla editada al notebook
python -m src.documentation.notebook_documenter apply-documentation \
  notebooks/01_eda.ipynb \
  notebooks/01_eda_doc_template.json \
  --output-path notebooks/01_eda_documented.ipynb
```

### Ejemplos

```bash
# Workflow completo de documentaci贸n
# 1. Generar plantilla
python -m src.documentation.notebook_documenter generate-template \
  notebooks/02_preprocessing.ipynb

# 2. Editar el archivo JSON generado manualmente

# 3. Aplicar documentaci贸n
python -m src.documentation.notebook_documenter apply-documentation \
  notebooks/02_preprocessing.ipynb \
  notebooks/02_preprocessing_doc_template.json

# 4. Agregar encabezado final
python -m src.documentation.notebook_documenter add-header \
  notebooks/02_preprocessing_documented.ipynb \
  --title "Preprocesamiento de Datos" \
  --author "Data Team" \
  --objective "Limpiar y transformar datos para modelado"
```

---

##  Workflow Completo Recomendado

### Paso 1: Entrenar Modelos y Generar M茅tricas
```bash
# Ya tienes esto con tu script de entrenamiento
python -m src.modeling.train --data-path data/processed/features.csv
```

### Paso 2: Generar Visualizaciones
```bash
# Para cada modelo entrenado
python -m src.visualization.plot_results generate-all-plots \
  --predictions-path data/processed/predictions.csv \
  --model-name "rf_model" \
  --output-dir reports/figures
```

### Paso 3: Comparar Modelos
```bash
# Comparar todos los modelos
python -m src.evaluation.compare_models compare \
  --metrics-dir reports/metrics \
  --output-dir reports/comparison
```

### Paso 4: Documentar Notebooks
```bash
# Para cada notebook
python -m src.documentation.notebook_documenter add-header \
  notebooks/03_training.ipynb \
  --title "Entrenamiento de Modelos" \
  --author "ML Team" \
  --objective "Entrenar y evaluar modelos de clasificaci贸n"
```

---

##  Requisitos

Aseg煤rate de tener instaladas las dependencias:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn typer loguru tabulate
```

O con uv:

```bash
uv pip install pandas numpy matplotlib seaborn scikit-learn typer loguru tabulate
```

---

##  Troubleshooting

### Error: "No se encontraron m茅tricas"
- Verifica que los archivos JSON est茅n en `reports/metrics/`
- Revisa que tengan la estructura correcta

### Error: "Columna 'popular' no encontrada"
- Aseg煤rate de que tu CSV de predicciones incluya la columna target
- O modifica el script para usar otra columna

### Gr谩ficos no se generan
- Verifica que matplotlib est茅 instalado correctamente
- En servidores sin GUI, usa backend 'Agg': `matplotlib.use('Agg')`

---
